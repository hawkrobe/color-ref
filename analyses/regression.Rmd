---
title: "R Notebook"
output: html_notebook
---

```{r}
library(tidyverse)
library(knitr)
library(scales)
library(xtable)
library(broom)
```

```{r}
d = read_csv('../data/norming/compiled-variance-entropy-glasgowRatings.csv') 
```

```{r}
filteredData = d %>%
  filter(imageability != 'N/A') %>%
  mutate(imageability = as.numeric(imageability),
         concreteness = as.numeric(concreteness))
```
# visualize variables

```{r}
filteredData %>%
  mutate(log_variance = log(variance)) %>%
  pivot_longer(-word) %>%
  ggplot(aes(x = value)) +
    geom_histogram() +
    facet_wrap(~ name, scales='free') +
    theme_few()
```

```{r}
scatter.smooth(x=filteredData$variance, y=filteredData$imageability)
scatter.smooth(x=filteredData$variance, y=filteredData$concreteness)
scatter.smooth(x=filteredData$entropy, y=filteredData$imageability)
scatter.smooth(x=filteredData$entropy, y=filteredData$concreteness)
```

# Examine relationship between DVs

```{r}
cor(filteredData$entropy, filteredData$variance, method = 'spearman')
cor(filteredData$entropy, filteredData$concreteness, method = 'spearman')
cor(filteredData$entropy, filteredData$imageability, method = 'spearman')
```

# Build and diagnose linear model for IMAGEABILITY

```{r}
# correlation
cat('variance-imageability correlation = ', cor(filteredData$variance, filteredData$imageability))
cor.test(filteredData$variance, filteredData$imageability)

# get summary stats
linearModIMAG <- lm(log(variance) ~ imageability, data=filteredData) # imageability as a function of variance
imagSummary <- summary(linearModIMAG) # capture model summary as an object
print(imagSummary)

# calculate summary stats for practice
imagCoeffs <- imagSummary$coefficients # model coefficients
beta.estimate <- imagCoeffs["variance", "Estimate"]  # get beta estimate for variance
std.error <- imagCoeffs["variance", "Std. Error"]  # get std.error for variance

t_value_imag <- beta.estimate/std.error  # calc t statistic
# larger t-value indicates that it is less likely that the coefficient is not equal to zero purely by chance

p_value_imag <- 2*pt(-abs(t_value), df=nrow(filteredData)-ncol(filteredData))  # calc p Value
# when p Value is less than significance level (< 0.05), we can safely reject the null hypothesis that the co-efficient Î² of the predictor is zero

f_statistic <- linearModIMAG$fstatistic[1]  # fstatistic
f <- summary(linearModIMAG)$fstatistic  # parameters for model p-value calc
model_p <- pf(f[1], f[2], f[3], lower=FALSE)
```

# Build and diagnose linear model for CONCRETENESS
```{r}
# correlation
cat('entropy-concreteness correlation = ', cor(filteredData$entropy, filteredData$concreteness))
cat('concreteness-imagability correlation = ', cor(filteredData$imageability, filteredData$concreteness))
cor.test(filteredData$entropy, filteredData$concreteness)

# get summary stats
# concreteness as a function of variance
linearModImg <- filteredData %>%
  lm(log(entropy) ~ imageability,
     data = .)

linearModConcrete <- filteredData %>%
  lm(log(entropy) ~ concreteness, 
     data=.) 

linearModBoth <- filteredData %>%
  lm(log(entropy) ~ imageability + concreteness,
     data=.) 

anova(linearModImg, linearModBoth)
anova(linearModConcrete, linearModBoth)
cncSummary <- summary(linearModBoth)
print(cncSummary)
```

```{r}
linearMod <- lm(variance ~ imageability + concreteness, data=filteredData)
print(summary(linearMod))

linearMod <- lm(entropy ~ imageability + concreteness, data=filteredData)
print(summary(linearMod))
```



# Attempt at mixed effects model
http://www.bodowinter.com/uploads/1/2/9/3/129362560/bw_lme_tutorial2.pdf
```{r}
library(lme4)

mixedModel <- lmer(imageability ~ variance + (1|word), data=filteredData, control=lmerControl(check.nobs.vs.nlev = "ignore", check.nobs.vs.rankZ = "ignore", check.nobs.vs.nRE="ignore"))
summary(mixedModel)
```

```{r}
ordered <- filteredData[order( filteredData[,3] ),]
barplot(ordered$entropy, main="Entropy", xlab="words")
```


