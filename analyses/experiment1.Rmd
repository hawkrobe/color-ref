---
title: "R Notebook"
output: html_notebook
---

# Import libraries

```{r}
library(tidyverse)
library(knitr)
library(scales)
library(xtable)
library(ggrepel)
```

# Import raw data

```{r}
d.raw = read_csv('../data/norming/color.csv') 
```

Only include participants who completed exactly 89 color-picker trials (all 80 words + 9 practice/catch trials)

```{r}
complete_ids = d.raw %>%
  group_by(participantID) %>%
  tally() %>%
  filter(n == 89) %>% 
  pull(participantID)
```

Check how many people were removed on catch trials vs. just dropped out

```{r results='asis'}
d.raw.final_trial <- d.raw %>%
  group_by(participantID) %>%
  filter(trial_index == last(trial_index)) %>%
  group_by(condition) %>%
  tally() %>%
  spread(condition, n)

cat('we lost', d.raw.final_trial$block1_catch_trial, 'on the first block catch trial,\n',
    d.raw.final_trial$block2_catch_trial, 'on the second block catch trial,\n', 
    d.raw.final_trial$catch_trial_color_trials, 'on the practice trial catch\n for a total of',
    d.raw.final_trial$catch_trial_color_trials
      + d.raw.final_trial$block1_catch_trial
      + d.raw.final_trial$block2_catch_trial)
```

Exclude based on colorblindness & RT

```{r}
# plate2 => normal = ['8' => key 56], red-green = ['3' => key 51]
# plate4 => normal = ['5' => key 53], red-green = ['2' => key 50]
# plate5 => normal = ['3' => key 51], red-green = ['5' => key 53]
colorblind_ids = read_csv('../data/norming/colorblindness.csv') %>%
  filter(participantID %in% complete_ids) %>%
  filter(case_when(stimulus == 2 ~ key_press != 56 & key_press != 51,
                   stimulus == 4 ~ key_press != 53 & key_press != 50,
                   stimulus == 5 ~ key_press != 51 & key_press != 53)) %>%
  pull(participantID) %>%
  unique()

cat('removed another', colorblind_ids %>% length(), 'for colorblindness') 

response_streak_ids <- d.raw %>%
  filter(participantID %in% complete_ids) %>%
  filter(!(participantID %in% colorblind_ids)) %>%
  filter(condition %in% c('block1_target_trial', 'block2_target_trial')) %>%
  group_by(participantID) %>%
  arrange(participantID,trial_index) %>%
  mutate(sameResponseAsPreviousTrial = lag(button_pressed) == button_pressed,
         threeInARow = paste0(lag(sameResponseAsPreviousTrial),
                              sameResponseAsPreviousTrial,
                              lead(sameResponseAsPreviousTrial)) == 'TRUETRUETRUE',
         m = mean(sameResponseAsPreviousTrial, na.rm = T)) %>%
  filter(threeInARow) %>%
  pull(participantID) %>%
  unique()

cat('removed another', response_streak_ids %>% length(), 'for colorblindness') 
```

Filter & check how balanced across words this leaves us

```{r}
d <- d.raw %>%
  filter(participantID %in% complete_ids) %>%
  filter(!(participantID %in% colorblind_ids)) %>%
  filter(!(participantID %in% response_streak_ids)) %>%
  filter(rt > 1000)

d %>%
  group_by(wordSetID, participantID) %>%
  tally() %>%
  group_by(wordSetID) %>%
  tally()

cat('including', length(unique(d$participantID)), 'complete games out of the', 
    length(unique(d.raw$participantID)), 'we recruited')
```

Save out filtered data:

```{r}
d %>%
  filter(trial_type == 'color-picker') %>%
  write_csv("../data/norming/colorPickerData.csv", row.names = TRUE)
```

Visualize color grids

```{r}
d %>%
  filter(trial_type == 'color-picker') %>%
  mutate(hex = rgb(response_r/255, response_g/255, response_b/255)) %>%
  group_by(word) %>%
  do(ggsave(.$word, device = 'png', plot = show_col(.$hex, labels = F)))
```

# Analysis 1: Compare expectations with ground truth metrics

## Examine relationship between variance and entropy

```{r}
dCompiled = read_csv('./experiment1/analysis1/compiled-variabilityMeasures-glasgowRatings.csv') 

filteredData = dCompiled %>%
  filter(imageability != 'N/A') %>%
  mutate(imageability = as.numeric(imageability),
         concreteness = as.numeric(concreteness))
```

## Visualize metrics
```{r}
scatter.smooth(x=filteredData$variance, y=filteredData$imageability)
scatter.smooth(x=filteredData$variance, y=filteredData$concreteness)
scatter.smooth(x=filteredData$entropy, y=filteredData$imageability)
scatter.smooth(x=filteredData$entropy, y=filteredData$concreteness)
```

## Examine relationship between DVs

```{r}
cor(filteredData$entropy, filteredData$variance, method = 'spearman')
cor(filteredData$entropy, filteredData$concreteness, method = 'spearman')
cor(filteredData$entropy, filteredData$imageability, method = 'spearman')
```

## Build and diagnose linear model for IMAGEABILITY

```{r}
# correlation
cat('variance-imageability correlation = ', cor(filteredData$variance, filteredData$imageability))
cor.test(filteredData$variance, filteredData$imageability)

# get summary stats
linearModIMAG <- lm(log(variance) ~ imageability, data=filteredData) # imageability as a function of variance
imagSummary <- summary(linearModIMAG) # capture model summary as an object
print(imagSummary)

# calculate summary stats for practice
imagCoeffs <- imagSummary$coefficients # model coefficients
beta.estimate <- imagCoeffs["variance", "Estimate"]  # get beta estimate for variance
std.error <- imagCoeffs["variance", "Std. Error"]  # get std.error for variance

t_value_imag <- beta.estimate/std.error  # calc t statistic
# larger t-value indicates that it is less likely that the coefficient is not equal to zero purely by chance

p_value_imag <- 2*pt(-abs(t_value), df=nrow(filteredData)-ncol(filteredData))  # calc p Value
# when p Value is less than significance level (< 0.05), we can safely reject the null hypothesis that the co-efficient Î² of the predictor is zero

f_statistic <- linearModIMAG$fstatistic[1]  # fstatistic
f <- summary(linearModIMAG)$fstatistic  # parameters for model p-value calc
model_p <- pf(f[1], f[2], f[3], lower=FALSE)
```

## Build and diagnose linear model for CONCRETENESS
```{r}
# correlation
cat('entropy-concreteness correlation = ', cor(filteredData$entropy, filteredData$concreteness))
cat('concreteness-imagability correlation = ', cor(filteredData$imageability, filteredData$concreteness))
cor.test(filteredData$entropy, filteredData$concreteness)

# get summary stats
# concreteness as a function of variance
linearModImg <- filteredData %>%
  lm(log(entropy) ~ imageability,
     data = .)

linearModConcrete <- filteredData %>%
  lm(log(entropy) ~ concreteness, 
     data=.) 

linearModBoth <- filteredData %>%
  lm(log(entropy) ~ imageability + concreteness,
     data=.) 

anova(linearModImg, linearModBoth)
anova(linearModConcrete, linearModBoth)
cncSummary <- summary(linearModBoth)
print(cncSummary)
```

```{r}
linearMod <- lm(variance ~ imageability + concreteness, data=filteredData)
print(summary(linearMod))

linearMod <- lm(entropy ~ imageability + concreteness, data=filteredData)
print(summary(linearMod))
```

## Attempt at mixed effects model
http://www.bodowinter.com/uploads/1/2/9/3/129362560/bw_lme_tutorial2.pdf
```{r}
library(lme4)

mixedModel <- lmer(imageability ~ variance + (1|word), data=filteredData, control=lmerControl(check.nobs.vs.nlev = "ignore", check.nobs.vs.rankZ = "ignore", check.nobs.vs.nRE="ignore"))
summary(mixedModel)
```

```{r}
ordered <- filteredData[order( filteredData[,3] ),]
barplot(ordered$entropy, main="Entropy", xlab="words")
```

# Analysis 2: Intra-participant variability

```{r}
dIntraparticipant = read_csv('./experiment1/analysis2/block1-block2-deltaE.csv') 
```

## Plot DeltaE for 5 lowest entropy words individually
```{r}
selectedWords <- filter(dIntraparticipant, word %in% c('lemon', 'sun', 'tomato', 'fire', 'apple', 'spinach', 'vegetable', 'tree', 'daffodil', 'bone'))

selectedWords %>%
  ggplot(aes(x = word, y = deltaE)) + 
  geom_violin() +
  geom_boxplot(width = 0.1) +
  labs(y="Delta E (CIE2000)", x = "Word") +
  ggtitle("Delta E between individual participants' block1 and block2 color response")
```
# Plot DeltaE for 5 highest entropy words individually
```{r}
selectedWords <- filter(dIntraparticipant, word %in% c('noun', 'misconception', 'peculiarity', 'tendency', 'obligation', 'randomness', 'oddity', 'complexity', 'responsibility', 'absurdity'))

selectedWords %>%
  ggplot(aes(x = word, y = deltaE)) + 
  geom_violin() +
  geom_boxplot(width = 0.1) +
  labs(y="Delta E (CIE2000)", x = "Word") +
  ggtitle("Delta E between individual participants' block1 and block2 color response")
```
# Average block1-block2 deltaE's for each word and plot
```{r}
averageDeltaE <- aggregate(dIntraparticipant[, 3], list(dIntraparticipant$word), mean) %>%
  rename(word = Group.1)

every_nth = function(n) {
  return(function(x) {x[c(TRUE, rep(FALSE, n - 1))]})
}
  
averageDeltaE %>%
  ggplot(aes(reorder(word, deltaE), deltaE))+
  geom_col() + 
  labs(x="Word", y= "Delta E (CIE2000)", title="Average Delta E between participants' block1 and block2 response") +
  theme(axis.text.x = element_text(size = 4, angle = 90), axis.title=element_text(size=8)) +
  theme(aspect.ratio=1/5) + 
  scale_x_discrete(breaks = every_nth(n = 2))

ggsave("./plots/average-block1-block2-deltaE.png", dpi=300, width=10, height=4)

```


# Analysis 3: Compare expectations with ground truth metrics

## Compare expectation (average slider response) to actual percent agreement
```{r}
dExpectation = read_csv('./experiment1/analysis3/expectation-by-condition.csv') 
dTruth = read_csv('./experiment1/analysis3/ground-truth-by-condition.csv') 

# Z score averages of expectation rating and actual percent matches (across participants) and compare
expectation <- aggregate(dExpectation[, 2], list(dExpectation$word), mean) %>% 
  mutate(zscore = (sliderResponse - mean(sliderResponse))/sd(sliderResponse)) %>%
  rename(word = "Group.1", avgExpectation = sliderResponse)

truth <-  aggregate(dTruth[, 2], list(dTruth$word), mean) %>% 
  mutate(zscore = (groundTruth - mean(groundTruth))/sd(groundTruth))

# plot word level responses (averaged over participants + z-scored)
scatter.smooth(x=expectation$zscore, y=truth$zscore, xlab="Average expecation rating", ylab="Average percent agreement", main="Expected agreement vs. actual agreement")
```
## Compare expectation (average slider response) to entropy
```{r}
# load and format entropy data
dEntropy = read_csv('./experiment1/analysis1/sorted-entropy-both.csv')

entropy <- dEntropy[order(dEntropy$word),] %>%
  mutate(entropy = as.numeric(entropy)) %>%
  mutate(zscore = (entropy - mean(entropy))/sd(entropy))
  
scatter.smooth(x=expectation$zscore, y=entropy$entropy, xlab = "Entropy of participants' color associations for all words", ylab = "Average % of population expected to share one's color association")

# correlation
cor.test(expectation$zscore, entropy$zscore)
```

## Compare expectation (average slider response) to DeltaE among participants' block 2 responses
```{r}
dDeltaE = read_csv('./experiment1/analysis3/sorted-deltaE-block2.csv') 

# zscoring:
deltaE <- dDeltaE[order(dDeltaE$word),] %>%
  mutate(zscore = (deltaE - mean(deltaE))/sd(deltaE))
# averaging slider + zscoring
expectation <- aggregate(dExpectation[, 2], list(dExpectation$word), mean) %>%
  rename(word = "Group.1", avgExpectation = sliderResponse) %>%
  mutate(zscore = (avgExpectation - mean(avgExpectation))/sd(avgExpectation))

# plot
scatter.smooth(x=expectation$zscore, y=deltaE$zscore, xlab="Average expecation rating", ylab="Average Delta E among block2 repsonses", main="Expected agreement vs. average Delta E")

# correlation
cor.test(expectation$zscore, deltaE$zscore)
```
## Expectation ratings vs. ground truth (calculated as percentage of total response that agreed with each participant's response)

The following analyses show that the ground truth agreements are much lower than the slider responses for expected agreement. Plotting the distributions of the expected and actual agreements for the 10 words with the least entropy in their prior distributions (i.e. most agreement), shows that only the words whose distributions would be expected to center around yellows, have an actual agreement that is somewhat reflective of their concreteness and expectation ratings. Meanwhile, the words whose response distributions would be expected to center on reds ("tomato", "fire", "apple") and greens ("spinach", "vegetable", "tree") have actual agreements that are much lower than expected. In the context of the munsell space that participants selected from--one which has a larger variety of red and green color choices, but very few yellow ones--this discrepancy suggests that when people rate their expected agreement they're considering the space of all reds, greens, etc. as "sharing" their color association (vs. the particular color they picked), but in reality words like "tomato" and "fire" and "vegetable" have many of different red or green responses that deflate the agreement.
```{r}
library("ggpubr")
ggboxplot(dExpectation, y = "sliderResponse", main= "Expected Agreement by Condition",
          color = "condition", order = c("concrete", "abstract"), ylim = c(0, 100),
          ylab = "% of population expected to share association") +
  theme(axis.ticks.x=element_blank(), axis.text.x=element_blank(), axis.title.x=element_blank())
```

### Ground truth boxplot
```{r}
ggboxplot(dTruth, y = "groundTruth", main= "Actual Agreement by Condition",
          color = "condition", order = c("concrete", "abstract"), ylim = c(0, 100),
          ylab = "% of population actually sharing color association") +
    theme(axis.ticks.x=element_blank(), axis.text.x=element_blank(), axis.title.x=element_blank())
```

### plotting expected and actual agreement for top 10 words individually
```{r}
# define "expected" and "actual" condition columns
expect <- rep(c("expected"),each=981)
actual <- rep(c("actual"),each=981)

# prepare datasets to be combined
selectedExpectation <- filter(dExpectation, word %in% c("lemon", "sun", "tomato", "fire", "apple", "spinach", "vegetable", "tree", "daffodil")) %>%
  subset(select=-condition) %>%
  rename(value = sliderResponse) %>%
  cbind(condition = expect)
  
selectedActual <- filter(dTruth, word %in% c("lemon", "sun", "tomato", "fire", "apple", "spinach", "vegetable", "tree", "daffodil")) %>%
  subset(select=-condition) %>%
  rename(value = groundTruth) %>%
  cbind(condition = actual)
# append datasets
both <- rbind(selectedActual, selectedExpectation)

# plot
ggplot(both, aes(x=word, y=value, fill=condition)) +
  geom_boxplot() +
  ggtitle("Actual vs. Expected Agreement") +
  labs(y="% agreement", x = "Word") +
  # facet_wrap(~condition) +
  coord_cartesian(ylim = c(0, 100)) +
  theme(axis.text.x = element_text(size = 10, angle = 45), axis.title=element_text(size=12))

```
## Logistic regression
```{r}
# takes a second to run
require(lme4)
dLogistic = read_csv('./experiment1/analysis3/logistic-regression.csv') 

m <- glmer(matchYN ~ aID1Expectation + (1 | aID1), data = dLogistic)
# print the mod results without correlations among fixed effects
print(m)
```

