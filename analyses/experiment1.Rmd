---
title: "R Notebook"
output: html_notebook
---

# Import libraries

```{r}
library(tidyverse)
library(knitr)
library(scales)
library(xtable)
library(ggrepel)
```

# Import raw data & implement exclusion criteria

```{r}
d.raw = read_csv('../data/norming/color.csv') 
```

Only include participants who completed exactly 89 color-picker trials (all 80 words + 9 practice/catch trials)

```{r}
complete_ids = d.raw %>%
  group_by(participantID) %>%
  tally() %>%
  filter(n == 89) %>% 
  pull(participantID)
```

Check how many people were removed on catch trials vs. just dropped out

```{r results='asis'}
d.raw.final_trial <- d.raw %>%
  group_by(participantID) %>%
  filter(trial_index == last(trial_index)) %>%
  group_by(condition) %>%
  tally() %>%
  spread(condition, n)

cat('we lost', d.raw.final_trial$block1_catch_trial, 'on the first block catch trial,\n',
    d.raw.final_trial$block2_catch_trial, 'on the second block catch trial,\n', 
    d.raw.final_trial$catch_trial_color_trials, 'on the practice trial catch\n for a total of',
    d.raw.final_trial$catch_trial_color_trials
      + d.raw.final_trial$block1_catch_trial
      + d.raw.final_trial$block2_catch_trial)
```

Exclude based on colorblindness & RT

```{r}
# plate2 => normal = ['8' => key 56], red-green = ['3' => key 51]
# plate4 => normal = ['5' => key 53], red-green = ['2' => key 50]
# plate5 => normal = ['3' => key 51], red-green = ['5' => key 53]
colorblind_ids = read_csv('../data/norming/colorblindness.csv') %>%
  filter(participantID %in% complete_ids) %>%
  filter(case_when(stimulus == 2 ~ key_press != 56 & key_press != 51,
                   stimulus == 4 ~ key_press != 53 & key_press != 50,
                   stimulus == 5 ~ key_press != 51 & key_press != 53)) %>%
  pull(participantID) %>%
  unique()

cat('removed another', colorblind_ids %>% length(), 'for colorblindness') 
```

```{r}
low_rt_ids <- d.raw %>%
  filter(participantID %in% complete_ids) %>%
  filter(!(participantID %in% colorblind_ids)) %>%
  filter(condition %in% c('block1_target_trial', 'block2_target_trial')) %>%
  group_by(participantID) %>%
  arrange(participantID,trial_index) %>%
  mutate(low_rt = rt < 1000) %>%
  summarize(m = mean(low_rt)) %>%
  filter(m > 0.25) %>%
  pull(participantID) %>%
  unique()

cat('removed another', low_rt_ids %>% length(), 'for consistently <1s rts') 

response_streak_ids <- d.raw %>%
  filter(participantID %in% complete_ids) %>%
  filter(!(participantID %in% colorblind_ids)) %>%
  filter(!(participantID %in% low_rt_ids)) %>%
  filter(condition %in% c('block1_target_trial', 'block2_target_trial')) %>%
  group_by(participantID) %>%
  arrange(participantID,trial_index) %>%
  mutate(sameResponseAsPreviousTrial = lag(button_pressed) == button_pressed,
         threeInARow = paste0(lag(sameResponseAsPreviousTrial),
                              sameResponseAsPreviousTrial,
                              lead(sameResponseAsPreviousTrial)) == 'TRUETRUETRUE',
         m = mean(sameResponseAsPreviousTrial, na.rm = T)) %>%
  filter(threeInARow) %>%
  pull(participantID) %>%
  unique()

cat('removed another', response_streak_ids %>% length(), 
    'for same response more than 3 in a row') 
```

Filter & check how balanced across words this leaves us

```{r}
d <- d.raw %>%
  filter(participantID %in% complete_ids) %>%
  filter(!(participantID %in% colorblind_ids)) %>%
  filter(!(participantID %in% response_streak_ids)) %>%
  filter(!(participantID %in% low_rt_ids))

d %>%
  group_by(wordSetID, participantID) %>%
  tally() %>%
  group_by(wordSetID) %>%
  tally()

cat('including', length(unique(d$participantID)), 'complete games out of the', 
    length(unique(d.raw$participantID)), 'we recruited')
```

Save out cleaned data for python scripts:

```{r}
write_csv(d, "../data/norming/colorPickerData.csv")
```

```{r}
# Uncomment to re-run python script; change path to your python binary / conda environment
# library(reticulate)
# use_python("/Users/roberthawkins/miniconda3/bin/python3", required = T)
# use_condaenv(condaenv = 'base')
# py_run_file("experiment1.py")
```

# Analysis 1: To what extent does concretentess/imageability predict variability

## Reproduced analysis

```{r}
colors <- d %>%
  cbind(c(.$response_r/255, .$response_g/255, .$response_b/255) %>%
        matrix(ncol = 3) %>%
        convertColor(from = 'sRGB', to = 'Lab') %>%
        data.frame()) %>%
  filter(condition %in% c('block1_target_trial', 'block2_target_trial')) %>%
  select(participantID, condition, word, L, a, b)

# get imageability and concreteness
glasgow <- read_csv('../data/norming/GlasgowNorms.csv') %>%
  mutate(word = case_when(word == 'bunk (bed)' ~ 'bunkbed',
                          word == 'absurd' ~ 'absurdity',
                          word == 'defiant' ~ 'defiance',
                          word == 'admire' ~ 'admiration',
                          word == 'adore' ~ 'adoration',
                          word == 'clear' ~ 'clarity',
                          word == 'complex' ~ 'complexity',
                          word == 'crazy' ~ 'craziness',
                          word == 'diverse' ~ 'diversity',
                          word == 'divine' ~ 'divinity',
                          word == 'elegant' ~ 'elegance',
                          word == 'friendly' ~ 'friendliness',
                          word == 'inflame' ~ 'inflamation',
                          word == 'modest' ~ 'modesty',
                          word == 'mystery' ~ 'mysterious',
                          word == 'obvious' ~ 'obviousness',
                          word == 'odd' ~ 'oddity',
                          word == 'peculiar' ~ 'peculiarity',
                          word == 'playful' ~ 'playfulness',
                          word == 'positive' ~ 'positivity',
                          word == 'random' ~ 'randomness',
                          word == 'real' ~ 'reality',
                          word == 'reassure' ~ 'reassurance',
                          word == 'relieved' ~ 'relief',
                          word == 'shy' ~ 'shyness',
                          word == 'thoughtless' ~ 'thoughtlessness',
                          word == 'vague' ~ 'vagueness',
                          word == 'vicious' ~ 'viciousness',
                          word == 'weary' ~ 'weariness',
                          TRUE ~ word)) %>%
  select(word, CNC, IMAG) %>%
  rename(concreteness = CNC,
         imageability = IMAG)

# get entropies
entropies <- d %>%
  filter(condition %in% c('block1_target_trial', 'block2_target_trial')) %>%
  group_by(word, button_pressed) %>%
  tally() %>%
  ungroup() %>%
  complete(button_pressed, word, fill = list(n = 0)) %>%
  group_by(word) %>%
  summarize(entropy = entropy::entropy(n, method = 'SG', unit="log2"))
  
# get pairwise distances
deltae <- colors %>%
  left_join(colors, by = c('word')) %>%
  filter(participantID.x != participantID.y) %>%
  mutate(prior_dist = spacesXYZ::DeltaE(matrix(c(L.x, a.x, b.x), ncol = 3), 
                                        matrix(c(L.y, a.y, b.y), ncol = 3), 
                                        metric = '2000')) %>%
  group_by(word) %>%
  summarize(prior_dist = mean(prior_dist))
```
## Compare computing deltaE by pooling both blocks' responses (prior_dist) to python calculation over only block1 (experiment 1, analysis 1)
```{r}
deltaE_block1 = read_csv('./experiment1/analysis1/sorted-deltaE-block1.csv') 

compare <- deltaE_block1[order(deltaE_block1$word),] %>%
  left_join(deltae) %>%
  rename(bothBlocks = prior_dist, block1 = deltaE)

compare$diff <- abs(compare$bothBlocks - compare$block1)

ggplot(compare, aes(x=word, y= diff, label=word))+
  geom_point(size = 1) +
  geom_text(aes(label=word),hjust=0, vjust=0, size=3)
cor(compare$bothBlocks, compare$block1)
sum(compare$diff > 1)
```


## Examine relationship between variance and entropy

```{r}
dCompiled_python = read_csv('./experiment1/analysis1/compiled-variabilityMeasures-glasgowRatings.csv') %>%
  filter(imageability != 'N/A') %>%
  mutate(imageability = as.numeric(imageability),
       concreteness = as.numeric(concreteness))

dCompiled <- entropies %>%
  left_join(deltae) %>%
  left_join(glasgow) %>%
  filter(!is.na(imageability))
```

### Visualize relationships between metrics / test correlations
```{r}
dCompiled_python %>% 
  select(-word) %>%
  GGally::ggpairs(lower = list(continuous = "smooth"), progress = F) + 
  ggthemes::theme_few()
```

```{r}
dCompiled %>% 
  select(-word) %>%
  GGally::ggpairs(lower = list(continuous = "smooth"), progress = F) + 
  ggthemes::theme_few()
```

### Compare regression models 

Some evidence for concreteness as non-redundant with imageability

```{r}
linearModImg <- dCompiled %>%
  lm(entropy ~ imageability,
     data = .)

linearModBoth <- dCompiled %>%
  lm(entropy ~ imageability + concreteness,
     data=.) 

anova(linearModImg, linearModBoth)

```
```{r}
linearModImg <- dCompiled %>%
  lm(prior_dist ~ imageability,
     data = .)

linearModBoth <- dCompiled %>%
  lm(prior_dist ~ imageability + concreteness,
     data=.) 

anova(linearModImg, linearModBoth)

```

But only when predicting entropy, not delta-e (if we include color-words)
Otherwise, ratings are non-redundant when predicting delta-E, not entropy. 

```{r}
linearMod <- lm(prior_dist ~ imageability + concreteness, data=dCompiled)
summary(linearMod)

linearMod <- lm(entropy ~ imageability + concreteness, data=dCompiled)
summary(linearMod)
```
```{r}
# filter out color words and get wordSetID for each word for mixed effects model

`%notin%` <- Negate(`%in%`)

wordset <- d %>%
  group_by(word) %>%
  filter(word %notin% c('red', 'orange', 'yellow', 'green', 'blue', 'purple', 'pink')) %>%
  filter(word %in% dCompiled$word) %>%
  summarize(wordSetID = mean(wordSetID)) %>%
  mutate(wordSetID = as.integer(wordSetID)) %>%
  mutate(wordSetID = as.numeric(wordSetID))


# include random effect of stimulus set
dCompiled['wordset'] <- wordset$wordSetID

linearMod <- lmer(prior_dist ~ imageability + concreteness + (1|wordset), data=dCompiled)
summary(linearMod)

linearMod <- lmer(entropy ~ imageability + concreteness + (1|wordset), data=dCompiled)
summary(linearMod)
```

## Analysis 2: Intra-participant variability

```{r}
dIntraparticipant_python = read_csv('./experiment1/analysis2/block1-block2-deltaE.csv') 

dIntraparticipant <- colors %>%
  separate(condition, into = c('block', 'trialtype')) %>%
  filter(block %in% c('block1', 'block2'), trialtype == 'target') %>%
  group_by(participantID, word) %>%
  pivot_wider(names_from = block, values_from = c('L', 'a', 'b')) %>%
  mutate(block1_block2_dist = spacesXYZ::DeltaE(matrix(c(L_block1, a_block1, b_block1), ncol = 3), 
                                        matrix(c(L_block2, a_block2, b_block2), ncol = 3), 
                                        metric = '2000')) 
```

```{r}
# get details of regression corresponding to figure 2B

x <- dIntraparticipant %>%
  group_by(word) %>%
  tidyboot::tidyboot_mean(block1_block2_dist, nboot = 100) %>%
  left_join(deltae) %>%
  rename(internal = empirical_stat, population = prior_dist)
  

# prior dist = average block1 delta E for each word (population variability)
# empirical_stat= average of individuals' block1-block2 delta E for each word (internal variability)
linearMod <- lm(internal ~ population, data=x)
summary(linearMod)

cor(x$internal, x$population)

linearMod <- lm(population ~ internal, data=x)
summary(linearMod)

```


# Average block1-block2 deltaE's for each word and plot

```{r}
dIntraparticipant %>%
  group_by(word) %>%
  tidyboot::tidyboot_mean(block1_block2_dist, nboot = 100) %>%
  left_join(deltae) %>%
  ggplot(aes(x = prior_dist, y = empirical_stat)) +
  geom_point() + 
  geom_abline(slope = 1, intercept = 0, linetype = 'dotted') +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0, alpha = 0.25) +
  geom_smooth(method = 'lm', formula = y ~ poly(x,1), color = 'red') +
  labs(x="Average delta E between different participants", 
       y= "Average delta E within participant") +
  xlim(0, 43) +
  ylim(0, 43) +
  ggthemes::theme_few() +
  theme(aspect.ratio = 1)

ggsave("./experiment1/figures/block1-block2-deltaE.pdf", width=4, height=3)
```

# Analysis 3: Compare expectations with ground truth metrics

## Compare expectation (average slider response) to actual percent agreement

```{r}
# Z score averages of expectation rating and actual percent matches (across participants) 
dLogistic = read_csv('./experiment1/analysis3/logistic-regression.csv')
dLogistic %>% 
  rename(participantID1 = aID1) %>%
  filter(participantID1 %in% d$participantID) %>%
  # Collapse to % match for each participant-word pair
  group_by(word, participantID1) %>%
  summarize(sliderResponse = mean(participantID1Expectation),
            groundTruth = mean(matchYN)) %>%
  # z-score slider responses within participant (i.e. expectation for this word relative to others)
  group_by(participantID1) %>%
  mutate(sliderResponse = scale(sliderResponse)) %>%
  gather(metric, value, sliderResponse:groundTruth) %>%
  group_by(word, metric) %>%
  # bootstrap error bars
  tidyboot::tidyboot_mean(value, nboot = 100) %>%
  select(-mean, -n) %>%
  pivot_wider( names_from = metric, values_from = c('empirical_stat', 'ci_lower', 'ci_upper')) %>%
  ggplot(aes(x = empirical_stat_sliderResponse, y = log(empirical_stat_groundTruth))) +
    geom_point() +
    geom_errorbarh(aes(xmax = ci_upper_sliderResponse, xmin = ci_lower_sliderResponse), alpha = 0.25) +
    geom_errorbar(aes(ymax = log(ci_upper_groundTruth), ymin = log(ci_lower_groundTruth)), alpha = 0.25) +
    geom_smooth(method = 'lm', formula = y ~ poly(x, 1), color = 'red') +
    labs(x = 'expectation', y = 'log P(agreement)') +
    ggthemes::theme_few() +
    theme(aspect.ratio = 1)

ggsave('./experiment1/figures/expectations.pdf', height = 3, width = 4, units = 'in')
```

## Compare expectation (average slider response) to entropy

```{r}
# load and format entropy data
dEntropy = read_csv('./experiment1/analysis1/sorted-entropy-both.csv')

entropy <- dEntropy[order(dEntropy$word),] %>%
  mutate(entropy = as.numeric(entropy)) %>%
  mutate(zscore = (entropy - mean(entropy))/sd(entropy))
  
scatter.smooth(x=expectation$zscore, y=entropy$entropy, xlab = "Entropy of participants' color associations for all words", ylab = "Average % of population expected to share one's color association")

# correlation
cor.test(expectation$zscore, entropy$zscore)
```

## Compare expectation (average slider response) to DeltaE among participants' block 2 responses

```{r}
dDeltaE = read_csv('./experiment1/analysis3/sorted-deltaE-block2.csv') 

# zscoring:
deltaE <- dDeltaE[order(dDeltaE$word),] %>%
  mutate(zscore = (deltaE - mean(deltaE))/sd(deltaE))
# averaging slider + zscoring
expectation <- aggregate(dExpectation[, 2], list(dExpectation$word), mean) %>%
  rename(word = "Group.1", avgExpectation = sliderResponse) %>%
  mutate(zscore = (avgExpectation - mean(avgExpectation))/sd(avgExpectation))

# plot
scatter.smooth(x=expectation$zscore, y=deltaE$zscore, xlab="Average expecation rating", ylab="Average Delta E among block2 repsonses", main="Expected agreement vs. average Delta E")

# correlation
cor.test(expectation$zscore, deltaE$zscore)
```
## Expectation ratings vs. ground truth (calculated as percentage of total response that agreed with each participant's response)

The following analyses show that the ground truth agreements are much lower than the slider responses for expected agreement. Plotting the distributions of the expected and actual agreements for the 10 words with the least entropy in their prior distributions (i.e. most agreement), shows that only the words whose distributions would be expected to center around yellows, have an actual agreement that is somewhat reflective of their concreteness and expectation ratings. Meanwhile, the words whose response distributions would be expected to center on reds ("tomato", "fire", "apple") and greens ("spinach", "vegetable", "tree") have actual agreements that are much lower than expected. In the context of the munsell space that participants selected from--one which has a larger variety of red and green color choices, but very few yellow ones--this discrepancy suggests that when people rate their expected agreement they're considering the space of all reds, greens, etc. as "sharing" their color association (vs. the particular color they picked), but in reality words like "tomato" and "fire" and "vegetable" have many of different red or green responses that deflate the agreement.
```{r}
library("ggpubr")
ggboxplot(dExpectation, y = "sliderResponse", main= "Expected Agreement by Condition",
          color = "condition", order = c("concrete", "abstract"), ylim = c(0, 100),
          ylab = "% of population expected to share association") +
  theme(axis.ticks.x=element_blank(), axis.text.x=element_blank(), axis.title.x=element_blank())
```

### Ground truth boxplot
```{r}
ggboxplot(dTruth, y = "groundTruth", main= "Actual Agreement by Condition",
          color = "condition", order = c("concrete", "abstract"), ylim = c(0, 100),
          ylab = "% of population actually sharing color association") +
    theme(axis.ticks.x=element_blank(), axis.text.x=element_blank(), axis.title.x=element_blank())
```

### plotting expected and actual agreement for top 10 words individually
```{r}
# define "expected" and "actual" condition columns
expect <- rep(c("expected"),each=981)
actual <- rep(c("actual"),each=981)

# prepare datasets to be combined
selectedExpectation <- filter(dExpectation, word %in% c("lemon", "sun", "tomato", "fire", "apple", "spinach", "vegetable", "tree", "daffodil")) %>%
  subset(select=-condition) %>%
  rename(value = sliderResponse) %>%
  cbind(condition = expect)
  
selectedActual <- filter(dTruth, word %in% c("lemon", "sun", "tomato", "fire", "apple", "spinach", "vegetable", "tree", "daffodil")) %>%
  subset(select=-condition) %>%
  rename(value = groundTruth) %>%
  cbind(condition = actual)
# append datasets
both <- rbind(selectedActual, selectedExpectation)

# plot
ggplot(both, aes(x=word, y=value, fill=condition)) +
  geom_boxplot() +
  ggtitle("Actual vs. Expected Agreement") +
  labs(y="% agreement", x = "Word") +
  # facet_wrap(~condition) +
  coord_cartesian(ylim = c(0, 100)) +
  theme(axis.text.x = element_text(size = 10, angle = 45), axis.title=element_text(size=12))

```
## Logistic regression
```{r}
# takes a second to run
require(lme4)

m <- glmer(matchYN ~ aID1Expectation + (1 | aID1), data = dLogistic)
# print the mod results without correlations among fixed effects
print(m)
```


# Supplemental

Visualize color grids

```{r}
d %>%
  mutate(hex = rgb(response_r/255, response_g/255, response_b/255)) %>%
  group_by(word) %>%
  do(ggsave(filename = paste0('color_grids/', .$word, '.png'), device = 'png', 
            plot = show_col(.$hex, labels = F)))
```

Visualize entropies

```{r}
ordered <- dCompiled[order( dCompiled$entropy ),]
barplot(ordered$entropy, main="Entropy", xlab="words")
```

Plot DeltaE for all words

```{r}
dIntraparticipant %>%
  mutate(word = factor(word)) %>%
  ggplot(aes(x = fct_reorder(word, block1_block2_dist), y = block1_block2_dist)) + 
    geom_boxplot(width = 1) +
    labs(y="Delta E (CIE2000)", x = "Word") + 
    guides(x = guide_axis(n.dodge = 1, angle = 90, check.overlap = T)) +
    ggtitle("Delta E between individual participants' block1 and block2 color response") +
    ggthemes::theme_few() +
    theme(aspect.ratio = 1/5) 
```
